# ðŸš€ DEPLOY DO SCRAPER PYTHON - PASSO A PASSO

## âœ… O que foi feito:

1. âœ… Corrigido `entrypoint.sh` para iniciar API FastAPI corretamente
2. âœ… Adicionado serviÃ§o `scraper` ao `docker-compose.yml`
3. âœ… Configurado health check e volumes compartilhados

---

## ðŸ“‹ INSTRUÃ‡Ã•ES PARA DEPLOY NA VPS

### 1. Atualizar cÃ³digo na VPS

```bash
cd /opt/brieflow
git pull github main
```

### 2. Build e iniciar o scraper

```bash
# Build da imagem do scraper
docker compose build scraper

# Iniciar o serviÃ§o
docker compose up -d scraper

# Verificar logs
sleep 10
docker logs briefflow-scraper --tail 30
```

### 3. Verificar se estÃ¡ funcionando

```bash
# Testar health check
curl http://localhost:8000/health

# Ver container rodando
docker ps | grep briefflow-scraper
```

**Esperado:**
- Container status: `Up` (nÃ£o Restarting)
- Health check: JSON com status "healthy"
- Porta 8000 mapeada

### 4. Testar integraÃ§Ã£o com backend

```bash
# Testar se backend consegue acessar scraper
curl http://localhost:5000/api/health

# Ou testar diretamente do container backend
docker exec briefflow-app curl http://briefflow-scraper:8000/health
```

---

## ðŸ§ª TESTE COMPLETO

### Usar o script de diagnÃ³stico:

```bash
cd /opt/brieflow
./diagnose-system.sh
```

Ou testar manualmente:

```bash
# 1. Verificar todos os containers
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# 2. Testar scraper
curl http://localhost:8000/health
curl http://localhost:8000/info

# 3. Testar backend
curl http://localhost:5000/api/health

# 4. Listar clientes no scraper
curl http://localhost:8000/clients
```

---

## ðŸ”§ SOLUÃ‡ÃƒO DE PROBLEMAS

### Erro: "No such file or directory" no build

**SoluÃ§Ã£o:** Verificar se pasta scraper existe:
```bash
ls -la /opt/brieflow/scraper/
```

### Erro: Container restartando

**SoluÃ§Ã£o:** Ver logs:
```bash
docker logs briefflow-scraper --tail 50
```

### Erro: Porta 8000 em uso

**SoluÃ§Ã£o:** Ver o que estÃ¡ usando a porta:
```bash
sudo lsof -i :8000
docker ps --format "table {{.Names}}\t{{.Ports}}" | grep 8000
```

---

## ðŸ“Š FLUXO DE TRABALHO APÃ“S DEPLOY

### 1. No Frontend (Netlify):

1. Acesse: https://briefflow2.netlify.app
2. FaÃ§a login
3. Crie um cliente (se ainda nÃ£o tiver)
4. VÃ¡ em "Fontes" â†’ "Adicionar Fonte"
5. Adicione uma fonte RSS:
   - Nome: "BBC Tech"
   - URL: `https://feeds.bbci.co.uk/news/technology/rss.xml`
   - Tipo: RSS

### 2. Executar Scraping:

```bash
# Pelo frontend (botÃ£o "Executar Scraping")
# Ou via API diretamente:
curl -X POST http://localhost:8000/scrape \
  -H "Content-Type: application/json" \
  -d '{"client_ids": ["<client_id>"]}'
```

### 3. Verificar conteÃºdos coletados:

No frontend: "ConteÃºdos" â†’ devem aparecer artigos da BBC Tech

---

## ðŸŽ‰ PRÃ“XIMOS PASSOS

Depois que o scraper estiver rodando:

1. **Testar scraping manual** via frontend
2. **Verificar se conteÃºdos aparecem** na lista
3. **Gerar um brief** usando a IA (Claude)
4. **Adicionar mais fontes** (blogs, notÃ­cias)

---

## ðŸ†˜ PRECISA DE AJUDA?

Se encontrar problemas:

1. Verifique logs: `docker logs briefflow-scraper --tail 100`
2. Execute diagnÃ³stico: `./diagnose-system.sh`
3. Teste scraper: `python3 test-scraper.py`

**Execute os comandos acima e me informe se deu algum erro!** ðŸš€
